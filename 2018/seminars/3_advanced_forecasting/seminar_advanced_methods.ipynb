{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, Applied ML, Autumn 2018</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> Seminar #3: Compositions, NN, TS forecasting in Python\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Alexey Romanenko </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">alexromsput@gmail.com</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key words:** \n",
    "    - ARIMAX models, \n",
    "    - composition of forecasting algorigthms\n",
    "    - NN for TS foreacasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Plan </h3>\n",
    "* **HW1 solution** (20 minutes)\n",
    "* **Practice: realize compositions: ** (20 minutes)</span> \n",
    "  - Adaptive Selection  \n",
    "  - Adaptive Composition \n",
    "  - <span style=\"color:orange; font-size: 10pt\"> Aggregating Algorithm </span> (self-study)\n",
    "    \n",
    "* ** NN for forecasting energy consumption ** (30 minutes)\n",
    "  - Energy consumption data\n",
    "  - NN with Keras,\n",
    "  - Forecasting with Regression\n",
    "  \n",
    "* **TS Forecasting in Python **\n",
    "  - Facebook Prophet\n",
    "  - Pyflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas.tseries.offsets as ofs\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa import stattools\n",
    "\n",
    "import warnings as w\n",
    "import plotly.plotly as py\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> HW1 solution </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Discuss Check Questions\n",
    "* Forecasting with ARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Practice: realize compositions</h1>\n",
    "# Adaptive selection\n",
    "** Question:**\n",
    "* What is adaptive selection?\n",
    "* Which external parameters does it have?\n",
    "* Describe case when adaptive selection works bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaptive_selection(x, h, params):\n",
    "'''\n",
    "Parameters\n",
    "x <array> - time series\n",
    "h <integer scalar>- forecasting delay\n",
    "params <dict> - dictionary with \n",
    "    gamma <scalar in [0,1]> - smoothing parameter of error\n",
    "    eps <scalar> - bound for best indistinctive models\n",
    "    base_algs - array of <dict> with params\n",
    "        base_alg <string> - name of base algorithm\n",
    "        BaseAlfParams <dict> dictionary of base algorithm's params\n",
    "'''\n",
    "    T = len(x)\n",
    "    FORECAST = [np.NaN]*(T+h)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Base Algs Forecasts     \n",
    "    base_algs = params.base_algs\n",
    "    N = len(base_algs)\n",
    "    FORECAST_BA = np.array([np.NAN]*(T+h)*N).reshape(N, T+h)\n",
    "    \n",
    "    \n",
    "    #     forecast TS by each base algs\n",
    "    #     be careful with eval() function    \n",
    "    for ba in range(len(base_algs)):\n",
    "        FORECAST_BA[BA]= eval(base_algs[ba]['base_alg']+\"(x,h,\"+\"base_algs[\"+str(ba)+\"]['base_alg_params'])\")\n",
    "    \n",
    "    # internal params of composition\n",
    "    gamma = params['gamma']\n",
    "    eps = params['eps']\n",
    "    \n",
    "    if gamma>1:\n",
    "        w.warn('Gamma can not be more than 1')\n",
    "        #alpha = 1\n",
    "        return FORECAST\n",
    "    if gamma<0:\n",
    "        w.warn('Gamma can not be less than 0')\n",
    "        #alpha = 0\n",
    "        return FORECAST\n",
    "\n",
    "    \n",
    "    e1= [0]*N  # initialization of errors of base algorithms \n",
    "    j_best = [0]*N\n",
    "    \n",
    "    \n",
    "    for t in range(0, T):\n",
    "        if not math.isnan(x[t]):\n",
    "            \n",
    "            if t>= h:\n",
    "                'TODO: check this code'\n",
    "                e1 = gamma*np.abs(x[t]-FORECAST_BA.transpose()[t])+(1-gamma)*e1  \n",
    "           \n",
    "                # select best algorithm at the moment t\n",
    "                j_best = 'TODO: find index of best base alg'\n",
    "                # select best indistinctive \n",
    "                idx_bestinsdistinctive = 'TODO: find indexes of best indistinctive algorithms'\n",
    "    \n",
    "                y = FORECAST_BA.transpose()[idx_bestinsdistinctive].mean()\n",
    "                # else do nothing\n",
    "#         else do nothing\n",
    "            \n",
    "            \n",
    "        FORECAST[t+h] = y\n",
    "    return FORECAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive composition\n",
    "** Question:**\n",
    "* What is adaptive composition?\n",
    "* Which external parameters does it have?\n",
    "* Describe case when adaptive selection works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaptive_composition(x, h, params):\n",
    "'''\n",
    "Parameters\n",
    "x <array> - time series\n",
    "h <integer scalar>- forecasting delay\n",
    "params <dict> - dictionary with \n",
    "    gamma <scalar in [0,1]> - smoothing parameter of error\n",
    "    base_algs - array of <dict> with params\n",
    "        base_alg <string> - name of base algorithm\n",
    "        base_alg_params <dict> dictionary of base algorithm's params\n",
    "'''\n",
    "    T = len(x)\n",
    "    FORECAST = [np.NaN]*(T+h)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Base Algs Forecasts     \n",
    "    base_algs = params.base_algs\n",
    "    N = len(base_algs)\n",
    "    FORECAST_BA = np.array([np.NAN]*(T+h)*N).reshape(N, T+h)\n",
    "    \n",
    "    \n",
    "    #     forecast TS by each base algs\n",
    "    #     be careful with eval() function    \n",
    "    for ba in range(len(base_algs)):\n",
    "        FORECAST_BA[BA]= eval(base_algs[ba]['base_alg']+\"(x,h,\"+\"base_algs[\"+str(ba)+\"]['base_alg_params'])\")\n",
    "    \n",
    "    # internal params of composition\n",
    "    gamma = params['gamma']\n",
    "    eps = params['eps']\n",
    "    \n",
    "    if gamma>1:\n",
    "        w.warn('Gamma can not be more than 1')\n",
    "        #alpha = 1\n",
    "        return FORECAST\n",
    "    if gamma<0:\n",
    "        w.warn('Gamma can not be less than 0')\n",
    "        #alpha = 0\n",
    "        return FORECAST\n",
    "\n",
    "    \n",
    "    e1= [0]*N  # initialization of errors of base algorithms \n",
    "    weights = [0]*N\n",
    "    \n",
    "    for t in range(0, T):\n",
    "        if not math.isnan(x[t]):\n",
    "            \n",
    "            if t>= h:\n",
    "                e1 = gamma*np.abs(x[t]-FORECAST_BA.transpose()[t])+(1-gamma)*e1\n",
    "           \n",
    "                # select best algorithm at the moment t\n",
    "                w_best = 'TODO: calculate weights of base algorithms'\n",
    "                \n",
    "#               Calculate forecast of the composition\n",
    "                y = FORECAST_BA.transpose()[j_best].mean()\n",
    "                # else do nothing\n",
    "#         else do nothing\n",
    "            \n",
    "            \n",
    "        FORECAST[t+h] = y\n",
    "    return FORECAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_algs = [{'base_alg':'InitExponentialSmoothing', 'base_alg_params':{'alpha':0.1, 'AdaptationPeriod':10}},\n",
    "            {'base_alg':'AdaptiveExponentialSmoothing', 'base_alg_params':{'alpha':0.2,'gamma':0.01, 'AdaptationPeriod':10}}\n",
    "#                  {'base_alg':'AdaptiveSimpleExponentialSmoothing', 'base_alg_params':{'alpha':0.1, 'gamma':0.01}},\n",
    "#                 {'base_alg':'TheilWageSmoothing', 'base_alg_params':{'alpha':0.3, 'beta':0.9,'delta':0.9}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleExponentialSmoothing(x,h,base_algs[0]['base_alg_params'])\n",
      "AdaptiveExponentialSmoothing(x,h,base_algs[1]['base_alg_params'])\n"
     ]
    }
   ],
   "source": [
    "for ba in range(len(base_algs)):\n",
    "    print(base_algs[ba]['base_alg']+\"(x,h,\"+\"base_algs[\"+str(ba)+\"]['base_alg_params'])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = pd.read_csv('../2_ts_arima/data/TimeSeries_Data10.csv', sep=',', decimal='.', parse_dates=True, dayfirst=True, index_col='Dates')\n",
    "ts.index.names=['Timestamp']\n",
    "# ts = pd.read_csv('./data/TimeSeries_Data10.csv', sep=',', decimal='.')\n",
    "ts = ts.sort_index() # sort index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h =1 \n",
    "frc_ts = pd.DataFrame(index = ts.index.append(pd.date_range(ts.index[-1]+timedelta(1), ts.index[-1]+timedelta(h)))\n",
    "                      , columns = ts.columns)\n",
    "FRC_TS = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run Adaptive Selection\n",
    "gamma=0.01\n",
    "eps = 1.0\n",
    "\n",
    "for cntr in ts.columns:\n",
    "    frc_ts[cntr]= adaptive_selection(ts[cntr],h, {'gamma':gamma, 'eps': eps, 'base_alg_params':base_algs})\n",
    "FRC_TS['AS gamma %.2f eps %.2f' % (gamma, eps)] = frc_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run Adaptive Composition\n",
    "gamma=0.01\n",
    "\n",
    "for cntr in ts.columns:\n",
    "    frc_ts[cntr]= adaptive_composition(ts[cntr],h, {'gamma':gamma, 'base_alg_params':base_algs})\n",
    "FRC_TS['AC gamma %.2f' % (gamma)] = frc_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot loss of compositions\n",
    "ix = range(100)\n",
    "# compare ES methods in first 100 steps\n",
    "QualityStr = pd.DataFrame(index = ts.columns, columns = sorted(FRC_TS.keys()))\n",
    "\n",
    "for model in QualityStr.columns:\n",
    "    frc_ts = FRC_TS[model]\n",
    "    for ts_num in ts.columns:\n",
    "        ix = pd.date_range(ts[ts_num].first_valid_index(), ts[ts_num].first_valid_index()+timedelta(50))\n",
    "        QualityStr[model][ts_num],_ = qualityMACAPE(ts[ts_num].loc[ix], frc_ts[ts_num].loc[ix])\n",
    "\n",
    "QualityStr[sorted(QualityStr.columns)[:1]].mean().plot(label='adaptive_composition', linewidth=2.0)\n",
    "QualityStr[sorted(QualityStr.columns)[1:2]].mean().plot(label='adaptive_selection', linewidth=2.0)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Algorithm\n",
    "** Question:**\n",
    "* What is aggregating algorithm?\n",
    "* What is a mixable game?\n",
    "* Descibe parameters of AA:\n",
    "    - $\\beta$ - parametr of mixability\n",
    "    - $S(g)$ - substitution function\n",
    "    - $p_j$ - initial distribution of base algorithms\n",
    "* Write down theoretical boundary for AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_composition(x, h, params):\n",
    "'''\n",
    "Parameters\n",
    "x <array> - time series\n",
    "h <integer scalar>- forecasting delay\n",
    "params <dict> - dictionary with \n",
    "    beta <scalar in [0,1]> - mixability parameter \n",
    "    weights <array in [0,1]> - initial weights of base_algs\n",
    "    base_algs - array of <dict> with params\n",
    "        base_alg <string> - name of base algorithm\n",
    "        base_alg_params <dict> dictionary of base algorithm's params\n",
    "'''\n",
    "    T = len(x)\n",
    "    FORECAST = [np.NaN]*(T+h)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Base Algs Forecasts     \n",
    "    base_algs = params.base_algs\n",
    "    N = len(base_algs)\n",
    "    FORECAST_BA = np.array([np.NAN]*(T+h)*N).reshape(N, T+h)\n",
    "    \n",
    "    \n",
    "    #     forecast TS by each base algs\n",
    "    #     be careful with eval() function    \n",
    "    for ba in range(len(base_algs)):\n",
    "        FORECAST_BA[BA]= eval(base_algs[ba]['base_alg']+\"(x,h,\"+\"base_algs[\"+str(ba)+\"]['base_alg_params'])\")\n",
    "    \n",
    "    # internal params of composition\n",
    "    beta = params['beta']\n",
    "    weights = params['weights']\n",
    "    \n",
    "    if beta>1:\n",
    "        w.warn('Gamma can not be more than 1')\n",
    "        #alpha = 1\n",
    "        return FORECAST\n",
    "    if beta<0:\n",
    "        w.warn('Gamma can not be less than 0')\n",
    "        #alpha = 0\n",
    "        return FORECAST\n",
    "\n",
    "           \n",
    "    for t in range(0, T):\n",
    "        if not math.isnan(x[t]):\n",
    "            \n",
    "            if t>= h:\n",
    "                weights = 'TODO: update weights'\n",
    "           \n",
    "                \n",
    "#               Calculate forecast of the composition\n",
    "                y = 'Substitution function'\n",
    "                \n",
    "         else:\n",
    "            y = 'Substitution function'\n",
    "            \n",
    "        FORECAST[t+h] = y\n",
    "    return FORECAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h =1 \n",
    "base_algs = [{'base_alg':'InitExponentialSmoothing', 'base_alg_params':{'alpha':0.1, 'AdaptationPeriod':10}},\n",
    "            {'base_alg':'AdaptiveExponentialSmoothing', 'base_alg_params':{'alpha':0.2,'gamma':0.01, 'AdaptationPeriod':10}}\n",
    "frc_ts = pd.DataFrame(index = ts.index.append(pd.date_range(ts.index[-1]+timedelta(1), ts.index[-1]+timedelta(h)))\n",
    "                      , columns = ts.columns)\n",
    "FRC_TS = dict()\n",
    "\n",
    "for cntr in ts.columns:\n",
    "    frc_ts[cntr]= aa_composition(ts[cntr],h, {'beta':0.9, 'weiths': np.array([0.5,0.5]), 'base_alg_params':base_algs})\n",
    "FRC_TS['AA beta %.2f' % (beta)] = frc_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> TS forecasting with NN </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "See [Keras_for_tsforecasting]()\n",
    "[данных](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align=\"center\"> TS forecasting in Python </h1>\n",
    "# Facebook Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real wage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-01-01</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-02-01</th>\n",
       "      <td>99.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-03-01</th>\n",
       "      <td>101.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-04-01</th>\n",
       "      <td>110.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-05-01</th>\n",
       "      <td>115.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Real wage\n",
       "Timestamp            \n",
       "1993-01-01     100.00\n",
       "1993-02-01      99.04\n",
       "1993-03-01     101.77\n",
       "1993-04-01     110.05\n",
       "1993-05-01     115.47"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Wage\n",
    "ts_wage = pd.read_csv('https://raw.githubusercontent.com/ml-mipt/ml-mipt-part2/master/2017/seminars/1_ts_esm/data/monthly-wage.csv', sep=';', decimal='.', parse_dates=True, index_col='Month')\n",
    "ts_wage.index.names=['Timestamp']\n",
    "# ts = pd.read_csv('./data/TimeSeries_Data10.csv', sep=',', decimal='.')\n",
    "ts_wage = ts_wage.sort_index() # sort index\n",
    "ts_wage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "my_model = Prophet(interval_width=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_wage.index.rename(name='ds', inplace=True)\n",
    "ts_wage.reset_index(inplace=True)\n",
    "ts_wage.rename(index=str, columns={'Real wage':'y', 'Timestamp':'ds'}, inplace=True)\n",
    "ts_wage.head()\n",
    "\n",
    "# fit model\n",
    "my_model.fit(ts_wage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates = my_model.make_future_dataframe(periods=12, freq='MS')\n",
    "future_dates.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = my_model.predict(future_dates)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Conclusion </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  * оцените <a href=\"https://goo.gl/forms/zSEynRUOCIO1SXv02\"> семинар </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
